import asyncio
import time
import sys
import os

# Add current directory to path to ensure modules can be imported
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import Config
from modules.scraper import get_driver, collect_new_posts
from modules.analyzer import TrumpAnalyzer
from modules.storage import Storage
from plyer import notification

def send_notification(count):
    try:
        notification.notify(
            title="ğŸš¨ ìƒˆë¡œìš´ íŠ¸ëŸ¼í”„ íŠ¸ìœ— ë°œê²¬!",
            message=f"{count}ê°œì˜ ì‹ ê·œ íŠ¸ìœ—ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.",
            app_name="Trump Tweet Analyzer",
            timeout=10
        )
    except Exception as e:
        print(f"âš ï¸ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

async def process_new_posts(new_posts, analyzer, storage):
    results = []
    print(f"\n{'='*60}")
    print(f"ğŸ¤– AI ë¶„ì„ ì‹œì‘: {len(new_posts)}ê°œ íŠ¸ìœ—")
    print(f"{'='*60}\n")

    for i, post in enumerate(new_posts, 1):
        print(f"\n[{i}/{len(new_posts)}] ë¶„ì„ ì¤‘...")
        analysis = await analyzer.analyze_tweet(post['content'])
        
        result_data = {
            'time': post['time'],          # US Time (Numeric/String)
            'posted_time': post['kst_time'], # KST Time String (time_str)
            'tweet_content': post['content'],
            'tweet_url': post.get('url', None),
            'impact_on_market': analysis.get('impact_on_market', 'Unknown'),
            'sentiment_score': analysis.get('sentiment_score', 0.0),
            'market_impact_score': analysis.get('market_impact_score', 0.0),
            'keywords': ', '.join(analysis.get('keywords', [])) if isinstance(analysis.get('keywords'), list) else str(analysis.get('keywords', '')),
            'sector': ', '.join(analysis.get('sector', [])) if isinstance(analysis.get('sector'), list) else str(analysis.get('sector', '')),
            'reason': analysis.get('reason', '')
        }
        results.append(result_data)

    # Save results
    storage.save_results(new_posts, results)

async def main_async():
    storage = Storage()
    analyzer = TrumpAnalyzer()
    
    # Load existing URLs to avoid duplicates
    existing_urls = storage.get_existing_urls()
    
    driver = get_driver()
    
    try:
        new_posts = collect_new_posts(driver, existing_urls, max_count=10)
        
        if new_posts:
            print(f"\nâœ… {len(new_posts)}ê°œ ì‹ ê·œ ê¸€ ë°œê²¬")
            
            # Save raw data first (cache)
            storage.save_raw_posts(new_posts)
            
            # Notify
            send_notification(len(new_posts))
            
            # Analyze and Save to DB/Excel
            await process_new_posts(new_posts, analyzer, storage)
            
        else:
            print("ğŸ”„ ì‹ ê·œ ê¸€ ì—†ìŒ")
            
    finally:
        driver.quit()

if __name__ == "__main__":
    print("ğŸš€ íŠ¸ëŸ¼í”„ íŠ¸ìœ— ë¶„ì„ ì—ì´ì „íŠ¸ ì‹œì‘ (Cloud Ready)")
    while True:
        try:
            asyncio.run(main_async())
            print("\nâ° 1ë¶„ í›„ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤...")
            time.sleep(60)
        except KeyboardInterrupt:
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            time.sleep(30)
